{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages (from transformers) (3.16.0)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zmey1/.local/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/zmey1/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.24.7\n",
      "    Uninstalling huggingface-hub-0.24.7:\n",
      "      Successfully uninstalled huggingface-hub-0.24.7\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.0\n",
      "    Uninstalling tokenizers-0.20.0:\n",
      "      Successfully uninstalled tokenizers-0.20.0\n",
      "Successfully installed huggingface-hub-0.29.3 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.49.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zmey1/anaconda3/envs/LLM/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-13 16:53:10.482497: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741864990.659649  746519 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741864990.708260  746519 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-13 16:53:11.154462: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MuRIL-based Farmer Conversation LLM...\n",
      "Loaded 4 soil types\n",
      "Loaded 5 crop types\n",
      "Loading MuRIL model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and running on cpu\n",
      "\n",
      "Farmer Conversation System using MuRIL LLM\n",
      "==========================================\n",
      "Type 'quit', 'exit', or 'reset' to start over.\n",
      "\n",
      "Start chatting below:\n",
      "\n",
      "\n",
      "Hello! I'm here to help calculate water requirements for your crops. Can you tell me about your farm?\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Red Soil soil, growing Rice, and your crop is in the initial stage. Is this correct?\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Red Soil soil, growing Rice, and your crop is in the initial stage. Is this correct?\n",
      "\n",
      "\n",
      "Great! Here's the information I'll send to calculate your water requirements:\n",
      "{\n",
      "  \"soil_type\": \"Black Clayey Soil\",\n",
      "  \"crop_type\": \"Sugarcane\",\n",
      "  \"growth_stage\": \"development\",\n",
      "  \"planting_info\": {\n",
      "    \"type\": \"days_ago\",\n",
      "    \"value\": 60\n",
      "  },\n",
      "  \"weather\": {\n",
      "    \"temperature\": 32.0,\n",
      "    \"humidity\": 75.0,\n",
      "    \"wind_speed\": 2.5,\n",
      "    \"rainfall\": 3.0\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Black Clayey Soil soil, growing Sugarcane, and your crop is in the development stage. Is this correct?\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Black Clayey Soil soil, growing Sugarcane, and your crop is in the development stage. Is this correct?\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Red Soil soil, growing Rice, and your crop is in the initial stage. Is this correct?\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Black Clayey Soil soil, growing Sugarcane, and your crop is in the development stage. Is this correct?\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Red Soil soil, growing Rice, and your crop is in the initial stage. Is this correct?\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Black Clayey Soil soil, growing Sugarcane, and your crop is in the development stage. Is this correct?\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Black Clayey Soil soil, growing Sugarcane, and your crop is in the development stage. Is this correct?\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Black Clayey Soil soil, growing Sugarcane, and your crop is in the development stage. Is this correct?\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Black Clayey Soil soil, growing Sugarcane, and your crop is in the development stage. Is this correct?\n",
      "\n",
      "\n",
      "Thank you for providing the information. Let me confirm: you have Black Clayey Soil soil, growing Sugarcane, and your crop is in the development stage. Is this correct?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Load CSV data\n",
    "def load_csv_data():\n",
    "    \"\"\"Load all required CSV datasets\"\"\"\n",
    "    soil_df = pd.read_csv('soil_properties.csv')\n",
    "    crop_df = pd.read_csv('crop_properties.csv')\n",
    "    constants_df = pd.read_csv('krishnan_kovil_constants.csv')\n",
    "    \n",
    "    print(f\"Loaded {len(soil_df)} soil types\")\n",
    "    print(f\"Loaded {len(crop_df)} crop types\")\n",
    "    \n",
    "    return soil_df, crop_df, constants_df\n",
    "\n",
    "# Tamil language mappings\n",
    "tamil_soil_mappings = {\n",
    "    'சிவப்பு மண்': 'Red Soil',\n",
    "    'கருப்பு களிமண்': 'Black Clayey Soil',\n",
    "    'பழுப்பு மண்': 'Brown Soil',\n",
    "    'வண்டல் மண்': 'Alluvial Soil'\n",
    "}\n",
    "\n",
    "tamil_crop_mappings = {\n",
    "    'நெல்': 'Rice',\n",
    "    'கரும்பு': 'Sugarcane',\n",
    "    'நிலக்கடலை': 'Groundnut',\n",
    "    'பருத்தி': 'Cotton',\n",
    "    'வாழை': 'Banana'\n",
    "}\n",
    "\n",
    "# Hardcoded weather data (to be replaced with API later)\n",
    "hardcoded_weather = {\n",
    "    'temperature': 32.0,  # °C\n",
    "    'humidity': 75.0,     # %\n",
    "    'wind_speed': 2.5,    # m/s\n",
    "    'rainfall': 3.0       # mm\n",
    "}\n",
    "\n",
    "class FarmerConversationLLM:\n",
    "    def __init__(self):\n",
    "        # Load datasets\n",
    "        self.soil_df, self.crop_df, self.constants_df = load_csv_data()\n",
    "        \n",
    "        # Initialize MuRIL model and tokenizer\n",
    "        print(\"Loading MuRIL model...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(\"google/muril-base-cased\")\n",
    "        \n",
    "        # Ensure model is in evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Initialize fill-mask pipeline for text completion\n",
    "        self.fill_mask = pipeline(\n",
    "            \"fill-mask\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer\n",
    "        )\n",
    "        \n",
    "        # Move model to GPU if available\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        print(f\"Model loaded and running on {self.device}\")\n",
    "        \n",
    "        # Initialize conversation state\n",
    "        self.state = {\n",
    "            'soil_type': None,\n",
    "            'crop_type': None,\n",
    "            'growth_stage': None,\n",
    "            'planting_info': None,\n",
    "            'language': 'english',\n",
    "            'conversation_history': []\n",
    "        }\n",
    "        \n",
    "        # Define prompts for different conversation stages\n",
    "        self.prompts = {\n",
    "            'english': {\n",
    "                'greeting': \"Hello! I'm here to help calculate water requirements for your crops. Can you tell me about your farm?\",\n",
    "                'ask_soil': \"What type of soil do you have in your farm?\",\n",
    "                'ask_crop': \"What crop are you growing?\",\n",
    "                'ask_planting': \"When did you plant your crop?\",\n",
    "                'confirm': \"Thank you for providing the information. Let me confirm: you have {soil_type} soil, growing {crop_type}, and your crop is in the {growth_stage} stage. Is this correct?\",\n",
    "                'complete': \"Great! Here's the information I'll send to calculate your water requirements:\\n{data_json}\"\n",
    "            },\n",
    "            'tamil': {\n",
    "                'greeting': \"வணக்கம்! உங்கள் பயிர்களுக்கான நீர் தேவைகளை கணக்கிட நான் உதவுகிறேன். உங்கள் பண்ணையைப் பற்றி சொல்லுங்கள்?\",\n",
    "                'ask_soil': \"உங்கள் பண்ணையில் எந்த வகை மண் உள்ளது?\",\n",
    "                'ask_crop': \"நீங்கள் என்ன பயிர் வளர்க்கிறீர்கள்?\",\n",
    "                'ask_planting': \"எப்போது உங்கள் பயிரை நட்டீர்கள்?\",\n",
    "                'confirm': \"தகவல் வழங்கியதற்கு நன்றி. உறுதிப்படுத்துகிறேன்: உங்களிடம் {soil_type} மண் உள்ளது, {crop_type} வளர்க்கிறீர்கள், மற்றும் உங்கள் பயிர் {growth_stage} நிலையில் உள்ளது. இது சரியா?\",\n",
    "                'complete': \"அருமை! உங்கள் நீர் தேவைகளை கணக்கிட நான் அனுப்பும் தகவல்கள்:\\n{data_json}\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Load example conversations for similarity matching\n",
    "        self.example_conversations = self.load_example_conversations()\n",
    "    \n",
    "    def load_example_conversations(self):\n",
    "        \"\"\"Load example conversations for similarity matching\"\"\"\n",
    "        # These would ideally come from a database or file\n",
    "        examples = [\n",
    "            {\n",
    "                'english': \"I have red soil and I'm growing rice. I planted it 30 days ago.\",\n",
    "                'tamil': \"என்னிடம் சிவப்பு மண் உள்ளது, நான் நெல் பயிரிடுகிறேன். 30 நாட்களுக்கு முன் நட்டேன்.\",\n",
    "                'soil_type': 'Red Soil',\n",
    "                'crop_type': 'Rice',\n",
    "                'days_ago': 30\n",
    "            },\n",
    "            {\n",
    "                'english': \"My farm has black clayey soil and I'm growing sugarcane for 2 months now.\",\n",
    "                'tamil': \"என் பண்ணையில் கருப்பு களிமண் உள்ளது, நான் 2 மாதங்களாக கரும்பு வளர்க்கிறேன்.\",\n",
    "                'soil_type': 'Black Clayey Soil',\n",
    "                'crop_type': 'Sugarcane',\n",
    "                'days_ago': 60\n",
    "            },\n",
    "            {\n",
    "                'english': \"I'm a groundnut farmer. My soil is brown soil. Planted about 45 days back.\",\n",
    "                'tamil': \"நான் ஒரு நிலக்கடலை விவசாயி. என் மண் பழுப்பு மண். சுமார் 45 நாட்களுக்கு முன் நட்டேன்.\",\n",
    "                'soil_type': 'Brown Soil',\n",
    "                'crop_type': 'Groundnut',\n",
    "                'days_ago': 45\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Encode examples for faster similarity matching\n",
    "        for example in examples:\n",
    "            example['english_encoding'] = self.encode_text(example['english'])\n",
    "            example['tamil_encoding'] = self.encode_text(example['tamil'])\n",
    "        \n",
    "        return examples\n",
    "    \n",
    "    def detect_language(self, text):\n",
    "        \"\"\"Detect if text is in Tamil or English\"\"\"\n",
    "        tamil_chars = [c for c in text if '\\u0B80' <= c <= '\\u0BFF']\n",
    "        return 'tamil' if tamil_chars else 'english'\n",
    "    \n",
    "    def encode_text(self, text):\n",
    "        \"\"\"Encode text using MuRIL model\"\"\"\n",
    "        # Tokenize text\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Get hidden states\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs, output_hidden_states=True)\n",
    "            # Use last hidden state of [CLS] token as sentence embedding\n",
    "            hidden_states = outputs.hidden_states[-1]\n",
    "            cls_embedding = hidden_states[:, 0, :].cpu().numpy()\n",
    "        \n",
    "        return cls_embedding\n",
    "    \n",
    "    def find_most_similar_example(self, text):\n",
    "        \"\"\"Find the most similar example to the input text\"\"\"\n",
    "        text_encoding = self.encode_text(text)\n",
    "        language = self.detect_language(text)\n",
    "        \n",
    "        best_similarity = -1\n",
    "        best_example = None\n",
    "        \n",
    "        for example in self.example_conversations:\n",
    "            encoding_key = 'tamil_encoding' if language == 'tamil' else 'english_encoding'\n",
    "            example_encoding = example[encoding_key]\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            similarity = np.dot(text_encoding.flatten(), example_encoding.flatten()) / (\n",
    "                np.linalg.norm(text_encoding) * np.linalg.norm(example_encoding)\n",
    "            )\n",
    "            \n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_example = example\n",
    "        \n",
    "        # Only return if similarity is above threshold\n",
    "        if best_similarity > 0.7:\n",
    "            return best_example\n",
    "        return None\n",
    "    \n",
    "    def extract_entities(self, text):\n",
    "        \"\"\"Extract soil type, crop type, and planting information from text\"\"\"\n",
    "        results = {\n",
    "            'soil_type': None,\n",
    "            'crop_type': None,\n",
    "            'planting_info': None,\n",
    "            'growth_stage': None\n",
    "        }\n",
    "        \n",
    "        # Detect language\n",
    "        language = self.detect_language(text)\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Try to find similar example first for fast-path extraction\n",
    "        similar_example = self.find_most_similar_example(text)\n",
    "        if similar_example:\n",
    "            results['soil_type'] = similar_example['soil_type']\n",
    "            results['crop_type'] = similar_example['crop_type']\n",
    "            days_ago = similar_example['days_ago']\n",
    "            results['planting_info'] = {'type': 'days_ago', 'value': days_ago}\n",
    "            \n",
    "            # Determine growth stage using the crop information from similar example\n",
    "            if results['crop_type']:\n",
    "                results['growth_stage'] = self.determine_growth_stage(days_ago, results['crop_type'])\n",
    "            \n",
    "            return results\n",
    "        \n",
    "        # Extract soil type\n",
    "        # First check for Tamil soil names\n",
    "        if language == 'tamil':\n",
    "            for tamil_soil, english_soil in tamil_soil_mappings.items():\n",
    "                if tamil_soil in text:\n",
    "                    results['soil_type'] = english_soil\n",
    "                    break\n",
    "        \n",
    "        # Then check for English soil names\n",
    "        if not results['soil_type']:\n",
    "            for _, row in self.soil_df.iterrows():\n",
    "                soil_type = row['soil_type']\n",
    "                if soil_type.lower() in text_lower:\n",
    "                    results['soil_type'] = soil_type\n",
    "                    break\n",
    "            \n",
    "            # Check for alternative soil names\n",
    "            if not results['soil_type']:\n",
    "                soil_alternatives = {\n",
    "                    'red': 'Red Soil',\n",
    "                    'black': 'Black Clayey Soil',\n",
    "                    'brown': 'Brown Soil',\n",
    "                    'alluvial': 'Alluvial Soil',\n",
    "                    'clay': 'Black Clayey Soil'\n",
    "                }\n",
    "                \n",
    "                for alt, soil in soil_alternatives.items():\n",
    "                    if alt in text_lower:\n",
    "                        results['soil_type'] = soil\n",
    "                        break\n",
    "        \n",
    "        # Extract crop type\n",
    "        # First check for Tamil crop names\n",
    "        if language == 'tamil':\n",
    "            for tamil_crop, english_crop in tamil_crop_mappings.items():\n",
    "                if tamil_crop in text:\n",
    "                    results['crop_type'] = english_crop\n",
    "                    break\n",
    "        \n",
    "        # Then check for English crop names\n",
    "        if not results['crop_type']:\n",
    "            for _, row in self.crop_df.iterrows():\n",
    "                crop_type = row['crop']\n",
    "                if crop_type.lower() in text_lower:\n",
    "                    results['crop_type'] = crop_type\n",
    "                    break\n",
    "            \n",
    "            # Check for alternative crop names\n",
    "            if not results['crop_type']:\n",
    "                crop_alternatives = {\n",
    "                    'paddy': 'Rice',\n",
    "                    'groundnuts': 'Groundnut',\n",
    "                    'peanut': 'Groundnut',\n",
    "                    'sugarcanes': 'Sugarcane',\n",
    "                    'bananas': 'Banana'\n",
    "                }\n",
    "                \n",
    "                for alt, crop in crop_alternatives.items():\n",
    "                    if alt in text_lower:\n",
    "                        results['crop_type'] = crop\n",
    "                        break\n",
    "        \n",
    "        # Extract planting information (days since planting)\n",
    "        days_pattern = r'(\\d+)\\s+days?\\s+ago'\n",
    "        months_pattern = r'(\\d+)\\s+months?\\s+ago'\n",
    "        tamil_days_pattern = r'(\\d+)\\s+நாட்களுக்கு\\s+முன்'\n",
    "        \n",
    "        # Check for days ago pattern\n",
    "        days_match = re.search(days_pattern, text_lower)\n",
    "        if days_match:\n",
    "            days = int(days_match.group(1))\n",
    "            results['planting_info'] = {'type': 'days_ago', 'value': days}\n",
    "        \n",
    "        # Check for months ago pattern\n",
    "        if not results['planting_info']:\n",
    "            months_match = re.search(months_pattern, text_lower)\n",
    "            if months_match:\n",
    "                months = int(months_match.group(1))\n",
    "                days = months * 30  # Approximate\n",
    "                results['planting_info'] = {'type': 'days_ago', 'value': days}\n",
    "        \n",
    "        # Check for Tamil days pattern\n",
    "        if not results['planting_info'] and language == 'tamil':\n",
    "            tamil_days_match = re.search(tamil_days_pattern, text)\n",
    "            if tamil_days_match:\n",
    "                days = int(tamil_days_match.group(1))\n",
    "                results['planting_info'] = {'type': 'days_ago', 'value': days}\n",
    "        \n",
    "        # If we have planting info and crop type, determine growth stage\n",
    "        if results['planting_info'] and results['planting_info']['type'] == 'days_ago' and results['crop_type']:\n",
    "            days_ago = results['planting_info']['value']\n",
    "            results['growth_stage'] = self.determine_growth_stage(days_ago, results['crop_type'])\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def determine_growth_stage(self, days_ago, crop_type):\n",
    "        \"\"\"Determine growth stage based on days since planting and crop type\"\"\"\n",
    "        # Find the crop in our dataset\n",
    "        crop_row = self.crop_df[self.crop_df['crop'] == crop_type]\n",
    "        \n",
    "        if crop_row.empty:\n",
    "            return None\n",
    "        \n",
    "        # Get growth stage durations\n",
    "        initial_days = crop_row['stage_initial_days'].values[0]\n",
    "        development_days = crop_row['stage_development_days'].values[0]\n",
    "        mid_season_days = crop_row['stage_mid_season_days'].values[0]\n",
    "        \n",
    "        # Calculate cumulative days\n",
    "        initial_end = initial_days\n",
    "        development_end = initial_end + development_days\n",
    "        mid_season_end = development_end + mid_season_days\n",
    "        \n",
    "        # Determine stage\n",
    "        if days_ago <= initial_end:\n",
    "            return 'initial'\n",
    "        elif days_ago <= development_end:\n",
    "            return 'development'\n",
    "        elif days_ago <= mid_season_end:\n",
    "            return 'mid_season'\n",
    "        else:\n",
    "            return 'late_season'\n",
    "    \n",
    "    def get_next_required_info(self):\n",
    "        \"\"\"Determine what information we still need to ask for\"\"\"\n",
    "        if not self.state['soil_type']:\n",
    "            return 'soil_type'\n",
    "        elif not self.state['crop_type']:\n",
    "            return 'crop_type'\n",
    "        elif not self.state['growth_stage'] and not self.state['planting_info']:\n",
    "            return 'planting_info'\n",
    "        return None\n",
    "    \n",
    "    def get_completion_with_muril(self, prompt, max_length=50):\n",
    "        \"\"\"Use MuRIL to generate a conversational completion\"\"\"\n",
    "        # This is a workaround using a masked language model for completion\n",
    "        # Not ideal but can provide some variability in responses\n",
    "        \n",
    "        prompt = prompt.strip()\n",
    "        # Add mask token to end of prompt\n",
    "        completion_prompt = f\"{prompt} {self.tokenizer.mask_token}\"\n",
    "        \n",
    "        generated_text = prompt\n",
    "        \n",
    "        # Generate one token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Get model prediction for next token\n",
    "            fill_mask_results = self.fill_mask(completion_prompt)\n",
    "            next_token = fill_mask_results[0][\"token_str\"]\n",
    "            \n",
    "            # Break if end of sentence is reached\n",
    "            if next_token in ['.', '?', '!']:\n",
    "                generated_text += next_token\n",
    "                break\n",
    "            \n",
    "            # Add token to generated text\n",
    "            generated_text += \" \" + next_token\n",
    "            \n",
    "            # Update completion prompt\n",
    "            completion_prompt = f\"{generated_text} {self.tokenizer.mask_token}\"\n",
    "        \n",
    "        return generated_text\n",
    "    \n",
    "    def generate_response(self, user_input):\n",
    "        \"\"\"Generate response using the MuRIL model and conversation state\"\"\"\n",
    "        # Add user input to conversation history\n",
    "        self.state['conversation_history'].append({'role': 'user', 'content': user_input})\n",
    "        \n",
    "        # Detect language\n",
    "        language = self.detect_language(user_input)\n",
    "        self.state['language'] = language\n",
    "        lang_key = 'tamil' if language == 'tamil' else 'english'\n",
    "        \n",
    "        # Extract entities from user input\n",
    "        extracted_data = self.extract_entities(user_input)\n",
    "        \n",
    "        # Update conversation state with extracted data\n",
    "        if extracted_data['soil_type']:\n",
    "            self.state['soil_type'] = extracted_data['soil_type']\n",
    "        \n",
    "        if extracted_data['crop_type']:\n",
    "            self.state['crop_type'] = extracted_data['crop_type']\n",
    "        \n",
    "        if extracted_data['growth_stage']:\n",
    "            self.state['growth_stage'] = extracted_data['growth_stage']\n",
    "        \n",
    "        if extracted_data['planting_info']:\n",
    "            self.state['planting_info'] = extracted_data['planting_info']\n",
    "        \n",
    "        # Determine what to ask next\n",
    "        next_required = self.get_next_required_info()\n",
    "        \n",
    "        # Generate response based on conversation state\n",
    "        if not self.state['conversation_history'][:-1]:\n",
    "            # First message - greeting\n",
    "            response = self.prompts[lang_key]['greeting']\n",
    "        elif next_required == 'soil_type':\n",
    "            response = self.prompts[lang_key]['ask_soil']\n",
    "        elif next_required == 'crop_type':\n",
    "            response = self.prompts[lang_key]['ask_crop']\n",
    "        elif next_required == 'planting_info':\n",
    "            response = self.prompts[lang_key]['ask_planting']\n",
    "        else:\n",
    "            # We have all the information we need\n",
    "            if language == 'tamil':\n",
    "                tamil_soil = next((k for k, v in tamil_soil_mappings.items() if v == self.state['soil_type']), \n",
    "                                  self.state['soil_type'])\n",
    "                tamil_crop = next((k for k, v in tamil_crop_mappings.items() if v == self.state['crop_type']), \n",
    "                                 self.state['crop_type'])\n",
    "                \n",
    "                # Map growth stage to Tamil\n",
    "                growth_stage_tamil = {\n",
    "                    'initial': 'ஆரம்ப நிலை',\n",
    "                    'development': 'வளர்ச்சி நிலை',\n",
    "                    'mid_season': 'நடு பருவம்',\n",
    "                    'late_season': 'இறுதி பருவம்'\n",
    "                }\n",
    "                tamil_stage = growth_stage_tamil.get(self.state['growth_stage'], self.state['growth_stage'])\n",
    "                \n",
    "                # Format confirmation message\n",
    "                response = self.prompts[lang_key]['confirm'].format(\n",
    "                    soil_type=tamil_soil,\n",
    "                    crop_type=tamil_crop,\n",
    "                    growth_stage=tamil_stage\n",
    "                )\n",
    "            else:\n",
    "                # Format confirmation message in English\n",
    "                response = self.prompts[lang_key]['confirm'].format(\n",
    "                    soil_type=self.state['soil_type'],\n",
    "                    crop_type=self.state['crop_type'],\n",
    "                    growth_stage=self.state['growth_stage']\n",
    "                )\n",
    "            \n",
    "            # Check if user confirms the information\n",
    "            if 'yes' in user_input.lower() or 'correct' in user_input.lower() or 'சரி' in user_input:\n",
    "                # Prepare data for backend\n",
    "                backend_data = {\n",
    "                    'soil_type': self.state['soil_type'],\n",
    "                    'crop_type': self.state['crop_type'],\n",
    "                    'growth_stage': self.state['growth_stage'],\n",
    "                    'planting_info': self.state['planting_info'],\n",
    "                    'weather': hardcoded_weather\n",
    "                }\n",
    "                \n",
    "                # Format the data as JSON\n",
    "                data_json = json.dumps(backend_data, indent=2)\n",
    "                \n",
    "                # Return completion message with data\n",
    "                response = self.prompts[lang_key]['complete'].format(data_json=data_json)\n",
    "        \n",
    "        # Add response to conversation history\n",
    "        self.state['conversation_history'].append({'role': 'assistant', 'content': response})\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Reset the conversation state\"\"\"\n",
    "        self.state = {\n",
    "            'soil_type': None,\n",
    "            'crop_type': None,\n",
    "            'growth_stage': None,\n",
    "            'planting_info': None,\n",
    "            'language': 'english',\n",
    "            'conversation_history': []\n",
    "        }\n",
    "\n",
    "# Main function to run the chatbot\n",
    "def main():\n",
    "    # Initialize the conversation LLM\n",
    "    print(\"Initializing MuRIL-based Farmer Conversation LLM...\")\n",
    "    conversation_llm = FarmerConversationLLM()\n",
    "    \n",
    "    print(\"\\nFarmer Conversation System using MuRIL LLM\")\n",
    "    print(\"==========================================\")\n",
    "    print(\"Type 'quit', 'exit', or 'reset' to start over.\")\n",
    "    print(\"\\nStart chatting below:\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"> \")\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit']:\n",
    "            break\n",
    "        \n",
    "        if user_input.lower() == 'reset':\n",
    "            conversation_llm.reset_conversation()\n",
    "            print(\"Conversation reset. Let's start over.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            response = conversation_llm.generate_response(user_input)\n",
    "            print(f\"\\n{response}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            print(\"Sorry, I encountered an error. Let's try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
